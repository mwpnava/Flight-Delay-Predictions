{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../datasets/resampledDF.csv'\n",
    "df = pd.read_csv(path, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SCHEDULED_DEPATURE_HR</th>\n",
       "      <th>SCHEDULED_ARRIVAL_HR</th>\n",
       "      <th>AIRLINE_CODE</th>\n",
       "      <th>PRESSURE</th>\n",
       "      <th>PRESSURE_DEST</th>\n",
       "      <th>ORIGIN_AIRPORT_CODE</th>\n",
       "      <th>RH_DEST</th>\n",
       "      <th>RH</th>\n",
       "      <th>DESTINATION_AIRPORT_CODE</th>\n",
       "      <th>DEWPT_DEST</th>\n",
       "      <th>DEWPT</th>\n",
       "      <th>CATEGORY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>29.39</td>\n",
       "      <td>30.04</td>\n",
       "      <td>5</td>\n",
       "      <td>46.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>5</td>\n",
       "      <td>17.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>29.39</td>\n",
       "      <td>30.04</td>\n",
       "      <td>5</td>\n",
       "      <td>46.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>5</td>\n",
       "      <td>17.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>29.39</td>\n",
       "      <td>30.50</td>\n",
       "      <td>5</td>\n",
       "      <td>54.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>7</td>\n",
       "      <td>19.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>30.51</td>\n",
       "      <td>29.26</td>\n",
       "      <td>6</td>\n",
       "      <td>77.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>29.92</td>\n",
       "      <td>29.50</td>\n",
       "      <td>0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>2</td>\n",
       "      <td>20.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SCHEDULED_DEPATURE_HR  SCHEDULED_ARRIVAL_HR  AIRLINE_CODE  PRESSURE  \\\n",
       "0                      0                     5             3     29.39   \n",
       "1                      0                     5             0     29.39   \n",
       "2                      0                     5             3     29.39   \n",
       "3                      0                     6             0     30.51   \n",
       "4                      0                     8             0     29.92   \n",
       "\n",
       "   PRESSURE_DEST  ORIGIN_AIRPORT_CODE  RH_DEST    RH  \\\n",
       "0          30.04                    5     46.0  62.0   \n",
       "1          30.04                    5     46.0  62.0   \n",
       "2          30.50                    5     54.0  62.0   \n",
       "3          29.26                    6     77.0  56.0   \n",
       "4          29.50                    0     64.0  20.0   \n",
       "\n",
       "   DESTINATION_AIRPORT_CODE  DEWPT_DEST  DEWPT  CATEGORY  \n",
       "0                         5        17.0   25.0         0  \n",
       "1                         5        17.0   25.0         0  \n",
       "2                         7        19.0   25.0         0  \n",
       "3                         0        13.0   20.0         0  \n",
       "4                         2        20.0   18.0         0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_name = 'CATEGORY'\n",
    "features_names = df.columns.drop(target_name)\n",
    "X = df[features_names]\n",
    "y = df[target_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def count_matching_rows(X_test, X_train):\n",
    "    \"\"\"\n",
    "    Count the number of rows in X_test that are also present in X_train.\n",
    "    \"\"\"\n",
    "    count = 0\n",
    "    for row in X_test:\n",
    "        count += np.count_nonzero(np.all(X_train == row, axis=1))\n",
    "    return count\n",
    "\n",
    "\n",
    "matching_rows = count_matching_rows(X_test.values, X_train.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in X_test that are also present in X_train: 3607\n"
     ]
    }
   ],
   "source": [
    "#print matching_rows\n",
    "print(\"Number of rows in X_test that are also present in X_train: {}\".format(matching_rows))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit_time:  123.65931534767151\n",
      "predict_time:  11.108866214752197\n",
      "accuracy:  0.8662186962121989\n",
      "classification_report:                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.76      0.81    263450\n",
      "           1       0.86      0.93      0.90    438382\n",
      "\n",
      "    accuracy                           0.87    701832\n",
      "   macro avg       0.87      0.84      0.85    701832\n",
      "weighted avg       0.87      0.87      0.86    701832\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=100, #number of trees in the forest\n",
    "                            random_state=42,  #for reproducibility\n",
    "                            bootstrap=True, #bootstrap samples when building trees\n",
    "                            max_depth=None, #which is the same as having no limit\n",
    "                            max_features='sqrt', #max number of features considered for splitting a node\n",
    "                            min_samples_leaf=1, #min number of samples required to be at a leaf node\n",
    "                            min_samples_split=2, #min number of samples required to split an internal node\n",
    "                            criterion='gini', #measure of quality of a split\n",
    "                            class_weight=None, #which is the same as not using weights,\n",
    "                            min_weight_fraction_leaf=0.0, #min weighted fraction of the sum total of weights required to be at a leaf node\n",
    "                            ccp_alpha=0.0, #complexity parameter used for Minimal Cost-Complexity Pruning,\n",
    "                            max_samples=None, #max number of samples drawn from X to train each base estimator\n",
    "                            max_leaf_nodes=None, #grow trees with max_leaf_nodes in best-first fashion\n",
    "                            min_impurity_decrease=0.0, #a node will be split if this split induces a decrease of the impurity greater than or equal to this value\n",
    "                            n_jobs=-1) #number of jobs to run in parallel\n",
    "\n",
    "start = time.time()\n",
    "rf.fit(X_train, y_train)\n",
    "fit_time = time.time() - start\n",
    "\n",
    "start = time.time()\n",
    "y_pred = rf.predict(X_test)\n",
    "predict_time = time.time() - start\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "cls_report = classification_report(y_test, y_pred)\n",
    "\n",
    "print('fit_time: ', fit_time)\n",
    "print('predict_time: ', predict_time)\n",
    "print('accuracy: ', accuracy)\n",
    "print('classification_report: ', cls_report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit_time:  29.733886003494263\n",
      "predict_time:  0.4060947895050049\n",
      "accuracy:  0.7792776618905949\n",
      "classification_report:                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.69      0.70    263450\n",
      "           1       0.82      0.83      0.82    438382\n",
      "\n",
      "    accuracy                           0.78    701832\n",
      "   macro avg       0.76      0.76      0.76    701832\n",
      "weighted avg       0.78      0.78      0.78    701832\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#decision tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dt = DecisionTreeClassifier(random_state=42, #for reproducibility\n",
    "                            criterion='gini', #measure of quality of a split\n",
    "                            splitter='best', #strategy used to choose the split at each node\n",
    "                            max_depth=None, #which is the same as having no limit\n",
    "                            min_samples_split=2, #min number of samples required to split an internal node\n",
    "                            min_samples_leaf=1, #min number of samples required to be at a leaf node\n",
    "                            min_weight_fraction_leaf=0.0, #min weighted fraction of the sum total of weights required to be at a leaf node\n",
    "                            max_features=None, #which is the same as not using any features\n",
    "                            max_leaf_nodes=None, #grow trees with max_leaf_nodes in best-first fashion\n",
    "                            min_impurity_decrease=0.0, #a node will be split if this split induces a decrease of the impurity greater than or equal to this value\n",
    "                            ccp_alpha=0.0, #complexity parameter used for Minimal Cost-Complexity Pruning\n",
    "                            class_weight=None) #which is the same as not using weights\n",
    "\n",
    "start = time.time()\n",
    "dt.fit(X_train, y_train)\n",
    "fit_time = time.time() - start\n",
    "\n",
    "start = time.time()\n",
    "y_pred = dt.predict(X_test)\n",
    "predict_time = time.time() - start\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "cls_report = classification_report(y_test, y_pred)\n",
    "\n",
    "print('fit_time: ', fit_time)\n",
    "print('predict_time: ', predict_time)\n",
    "print('accuracy: ', accuracy)\n",
    "print('classification_report: ', cls_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit_time:  11.591121673583984\n",
      "predict_time:  44.256736516952515\n",
      "accuracy:  0.8480947007260997\n",
      "classification_report:                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.70      0.77    263450\n",
      "           1       0.84      0.94      0.89    438382\n",
      "\n",
      "    accuracy                           0.85    701832\n",
      "   macro avg       0.86      0.82      0.83    701832\n",
      "weighted avg       0.85      0.85      0.84    701832\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#KNN\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=7, #number of neighbors to use by default for kneighbors queries\n",
    "                            weights='uniform', #weight function used in prediction\n",
    "                            algorithm='auto', #algorithm used to compute the nearest neighbors\n",
    "                            leaf_size=30, #leaf size passed to BallTree or KDTree\n",
    "                            p=2, #power parameter for the Minkowski metric\n",
    "                            metric='minkowski', #the distance metric to use for the tree\n",
    "                            metric_params=None, #additional keyword arguments for the metric function\n",
    "                            n_jobs=-1) #number of parallel jobs to run\n",
    "\n",
    "start = time.time()\n",
    "knn.fit(X_train, y_train)\n",
    "fit_time = time.time() - start\n",
    "\n",
    "start = time.time()\n",
    "y_pred = knn.predict(X_test)\n",
    "predict_time = time.time() - start\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "cls_report = classification_report(y_test, y_pred)\n",
    "\n",
    "print('fit_time: ', fit_time)\n",
    "print('predict_time: ', predict_time)\n",
    "print('accuracy: ', accuracy)\n",
    "print('classification_report: ', cls_report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit_time:  12.496455669403076\n",
      "predict_time:  0.04300403594970703\n",
      "accuracy:  0.6525920733166912\n",
      "classification_report:                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.29      0.38    263450\n",
      "           1       0.67      0.87      0.76    438382\n",
      "\n",
      "    accuracy                           0.65    701832\n",
      "   macro avg       0.62      0.58      0.57    701832\n",
      "weighted avg       0.63      0.65      0.62    701832\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#logistic regression\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression(penalty='l2', #used to specify the norm used in the penalization\n",
    "                        dual=False, #select the algorithm to either solve the dual or primal optimization problem\n",
    "                        tol=0.0001, #tolerance for stopping criteria\n",
    "                        C=1.0, #inverse of regularization strength\n",
    "                        fit_intercept=True, #whether to calculate the intercept for this model\n",
    "                        intercept_scaling=1, #when self.fit_intercept is set to True, instance vector x becomes [x, self.intercept_scaling],\n",
    "                        class_weight=None, #which is the same as not using weights\n",
    "                        random_state=42, #for reproducibility\n",
    "                        solver='lbfgs', #algorithm to use in the optimization problem\n",
    "                        max_iter=100, #maximum number of iterations taken for the solvers to converge\n",
    "                        multi_class='auto', #if the option chosen is 'ovr', then a binary problem is fit for each label\n",
    "                        verbose=0, #for the liblinear and lbfgs solvers set verbose to any positive number for verbosity\n",
    "                        warm_start=False, #when set to True, reuse the solution of the previous call to fit as initialization,\n",
    "                        n_jobs=-1, #number of CPU cores used when parallelizing over classes if multi_class='ovr'\n",
    "                        l1_ratio=None) #the Elastic-Net mixing parameter, with 0 <= l1_ratio <= 1\n",
    "\n",
    "start = time.time()\n",
    "lr.fit(X_train, y_train)\n",
    "fit_time = time.time() - start\n",
    "\n",
    "start = time.time()\n",
    "y_pred = lr.predict(X_test)\n",
    "predict_time = time.time() - start\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "cls_report = classification_report(y_test, y_pred)\n",
    "\n",
    "print('fit_time: ', fit_time)\n",
    "print('predict_time: ', predict_time)\n",
    "print('accuracy: ', accuracy)\n",
    "print('classification_report: ', cls_report)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit_time:  0.5753827095031738\n",
      "predict_time:  0.2221391201019287\n",
      "accuracy:  0.648903156310912\n",
      "classification_report:                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.47      0.50    263450\n",
      "           1       0.70      0.76      0.73    438382\n",
      "\n",
      "    accuracy                           0.65    701832\n",
      "   macro avg       0.62      0.61      0.61    701832\n",
      "weighted avg       0.64      0.65      0.64    701832\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#  Gaussian Naive Bayes\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "gnb = GaussianNB(priors=None, #prior probabilities of the classes\n",
    "                var_smoothing=1e-09) #additive (Laplace/Lidstone) smoothing parameter\n",
    "\n",
    "start = time.time()\n",
    "gnb.fit(X_train, y_train)\n",
    "fit_time = time.time() - start\n",
    "\n",
    "start = time.time()\n",
    "y_pred = gnb.predict(X_test)\n",
    "predict_time = time.time() - start\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "cls_report = classification_report(y_test, y_pred)\n",
    "\n",
    "print('fit_time: ', fit_time)\n",
    "print('predict_time: ', predict_time)\n",
    "print('accuracy: ', accuracy)\n",
    "print('classification_report: ', cls_report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit_time:  521.5146534442902\n",
      "predict_time:  0.9267222881317139\n",
      "accuracy:  0.7140184545589258\n",
      "classification_report:                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.44      0.54    263450\n",
      "           1       0.72      0.88      0.79    438382\n",
      "\n",
      "    accuracy                           0.71    701832\n",
      "   macro avg       0.70      0.66      0.67    701832\n",
      "weighted avg       0.71      0.71      0.70    701832\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#gradient boosting\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "gb = GradientBoostingClassifier(loss='log_loss', #loss function to be optimized\n",
    "                                learning_rate=0.1, #learning rate shrinks the contribution of each tree by learning_rate\n",
    "                                n_estimators=100, #the number of boosting stages to perform\n",
    "                                subsample=1.0, #the fraction of samples to be used for fitting the individual base learners\n",
    "                                criterion='friedman_mse', #the function to measure the quality of a split\n",
    "                                min_samples_split=2, #the minimum number of samples required to split an internal node\n",
    "                                min_samples_leaf=1, #the minimum number of samples required to be at a leaf node\n",
    "                                min_weight_fraction_leaf=0.0, #the minimum weighted fraction of the sum total of weights (of all the input samples)\n",
    "                                max_depth=3, #maximum depth of the individual regression estimators\n",
    "                                min_impurity_decrease=0.0, #a node will be split if this split induces a decrease of the impurity greater than or equal to this value\n",
    "                                init=None, #an estimator object that is used to compute the initial predictions\n",
    "                                random_state=42, #for reproducibility\n",
    "                                max_features=None, #the number of features to consider when looking for the best split\n",
    "                                verbose=0, #enable verbose output\n",
    "                                max_leaf_nodes=None, #grow trees with max_leaf_nodes in best-first fashion\n",
    "                                warm_start=False, #when set to True, reuse the solution of the previous call to fit and add more estimators to the ensemble\n",
    "                                validation_fraction=0.1, #the proportion of training data to set aside as validation set for early stopping\n",
    "                                n_iter_no_change=None, #n_iter_no_change is used to decide if early stopping will be used to terminate training when validation score is not improving\n",
    "                                tol=0.0001, #tol is the threshold for measuring the increase of the validation score. If the increase is smaller than tol, the training stops\n",
    "                                ccp_alpha=0.0) #complexity parameter used for Minimal Cost-Complexity Pruning. The subtree with the largest cost complexity that is smaller than ccp_alpha will be chosen\n",
    "\n",
    "start = time.time()\n",
    "gb.fit(X_train, y_train)\n",
    "fit_time = time.time() - start\n",
    "\n",
    "start = time.time()\n",
    "y_pred = gb.predict(X_test)\n",
    "predict_time = time.time() - start\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "cls_report = classification_report(y_test, y_pred)\n",
    "\n",
    "print('fit_time: ', fit_time)\n",
    "print('predict_time: ', predict_time)\n",
    "print('accuracy: ', accuracy)\n",
    "print('classification_report: ', cls_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit_time:  928.0698595046997\n",
      "predict_time:  0.8160500526428223\n",
      "accuracy:  0.6849944146177432\n",
      "classification_report:                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.49      0.54    263450\n",
      "           1       0.72      0.80      0.76    438382\n",
      "\n",
      "    accuracy                           0.68    701832\n",
      "   macro avg       0.66      0.65      0.65    701832\n",
      "weighted avg       0.68      0.68      0.68    701832\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#NN\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "nn = MLPClassifier(hidden_layer_sizes=(100, ), #the ith element represents the number of neurons in the ith hidden layer\n",
    "                    activation='relu', #activation function for the hidden layer\n",
    "                    solver='adam', #the solver for weight optimization\n",
    "                    alpha=0.0001, #L2 penalty (regularization term) parameter\n",
    "                    batch_size='auto', #size of minibatches for stochastic optimizers\n",
    "                    learning_rate='constant', #learning rate schedule for weight updates\n",
    "                    learning_rate_init=0.001, #initial learning rate used\n",
    "                    power_t=0.5, #exponent for inverse scaling learning rate\n",
    "                    max_iter=200, #maximum number of iterations\n",
    "                    shuffle=True, #whether to shuffle samples in each iteration\n",
    "                    random_state=42, #for reproducibility\n",
    "                    tol=0.0001, #tolerance for the optimization\n",
    "                    verbose=False, #whether to print progress messages to stdout\n",
    "                    warm_start=False, #when set to True, reuse the solution of the previous call to fit as initialization\n",
    "                    momentum=0.9, #momentum for gradient descent update\n",
    "                    nesterovs_momentum=True, #whether to use Nesterov's momentum\n",
    "                    early_stopping=False, #whether to use early stopping to terminate training when validation score is not improving\n",
    "                    validation_fraction=0.1, #the proportion of training data to set aside as validation set for early stopping\n",
    "                    beta_1=0.9, #exponential decay rate for estimates of first moment vector in adam, should be in [0, 1)\n",
    "                    beta_2=0.999, #exponential decay rate for estimates of second moment vector in adam, should be in [0, 1)\n",
    "                    epsilon=1e-08, #value for numerical stability in adam\n",
    "                    n_iter_no_change=10, #maximum number of epochs to not meet tol improvement\n",
    "                    max_fun=15000) #maximum number of function evaluations\n",
    "\n",
    "start = time.time()\n",
    "nn.fit(X_train, y_train)\n",
    "fit_time = time.time() - start\n",
    "\n",
    "start = time.time()\n",
    "y_pred = nn.predict(X_test)\n",
    "predict_time = time.time() - start\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "cls_report = classification_report(y_test, y_pred)\n",
    "\n",
    "print('fit_time: ', fit_time)\n",
    "print('predict_time: ', predict_time)\n",
    "print('accuracy: ', accuracy)\n",
    "print('classification_report: ', cls_report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  1062\n",
      "gb:  123964\n",
      "nn:  37302\n",
      "knn:  177393365\n",
      "rf:  3555792005\n",
      "dt:  35759755\n"
     ]
    }
   ],
   "source": [
    "#save each models as a pickle file\n",
    "\n",
    "import datetime\n",
    "import pickle\n",
    "time_stamp = datetime.datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "pickle.dump(lr, open(f'lr_{time_stamp}.pkl', 'wb'))\n",
    "pickle.dump(gb, open(f'gb_{time_stamp}.pkl', 'wb'))\n",
    "pickle.dump(nn, open(f'nn_{time_stamp}.pkl', 'wb'))\n",
    "#knn\n",
    "pickle.dump(knn, open(f'knn_{time_stamp}.pkl', 'wb'))\n",
    "#rf - \n",
    "pickle.dump(rf, open(f'rf_{time_stamp}.pkl', 'wb'))\n",
    "#dt\n",
    "pickle.dump(dt, open(f'dt_{time_stamp}.pkl', 'wb'))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size in MB\n",
      "lr:  0.0010128021240234375\n",
      "gb:  0.11822128295898438\n",
      "nn:  0.03557395935058594\n",
      "knn:  169.1754961013794\n",
      "rf:  3391.067509651184\n",
      "dt:  34.10315990447998\n"
     ]
    }
   ],
   "source": [
    "#get sizes, in Bytes\n",
    "import os\n",
    "\n",
    "print('Size in MB')\n",
    "print('lr: ', os.path.getsize(f'lr_{time_stamp}.pkl')/1024/1024)\n",
    "print('gb: ', os.path.getsize(f'gb_{time_stamp}.pkl')/1024/1024)\n",
    "print('nn: ', os.path.getsize(f'nn_{time_stamp}.pkl')/1024/1024)\n",
    "print('knn: ', os.path.getsize(f'knn_{time_stamp}.pkl')/1024/1024)\n",
    "print('rf: ', os.path.getsize(f'rf_{time_stamp}.pkl')/1024/1024)\n",
    "print('dt: ', os.path.getsize(f'dt_{time_stamp}.pkl')/1024/1024)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution of classes in test set\n",
      "0    263450\n",
      "1    263450\n",
      "Name: CATEGORY, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "rus = RandomUnderSampler(sampling_strategy='majority', random_state=42)\n",
    "X_test_under, y_test_under = rus.fit_resample(X_test, y_test)\n",
    "\n",
    "#print distribution of classes\n",
    "print('Distribution of classes in test set')\n",
    "print(y_test_under.value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit_time:  10.144760847091675\n",
      "predict_time:  17.56206226348877\n",
      "accuracy:  0.9548524433197688\n",
      "classification_report:                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.91      0.94    263450\n",
      "           1       0.95      0.98      0.96    438382\n",
      "\n",
      "    accuracy                           0.95    701832\n",
      "   macro avg       0.96      0.94      0.95    701832\n",
      "weighted avg       0.96      0.95      0.95    701832\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#KNN\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=1, #number of neighbors to use by default for kneighbors queries\n",
    "                            weights='uniform', #weight function used in prediction\n",
    "                            algorithm='auto', #algorithm used to compute the nearest neighbors\n",
    "                            leaf_size=30, #leaf size passed to BallTree or KDTree\n",
    "                            p=2, #power parameter for the Minkowski metric\n",
    "                            metric='minkowski', #the distance metric to use for the tree\n",
    "                            metric_params=None, #additional keyword arguments for the metric function\n",
    "                            n_jobs=-1) #number of parallel jobs to run\n",
    "\n",
    "start = time.time()\n",
    "knn.fit(X_train, y_train)\n",
    "fit_time = time.time() - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit_time:  10.144760847091675\n",
      "predict_time:  15.7011079788208\n",
      "accuracy:  0.944754222812678\n",
      "classification_report:                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.91      0.94    263450\n",
      "           1       0.91      0.98      0.95    263450\n",
      "\n",
      "    accuracy                           0.94    526900\n",
      "   macro avg       0.95      0.94      0.94    526900\n",
      "weighted avg       0.95      0.94      0.94    526900\n",
      "\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "y_pred = knn.predict(X_test_under)\n",
    "predict_time = time.time() - start\n",
    "\n",
    "accuracy = accuracy_score(y_test_under, y_pred)\n",
    "cls_report = classification_report(y_test_under, y_pred)\n",
    "\n",
    "print('fit_time: ', fit_time)\n",
    "print('predict_time: ', predict_time)\n",
    "print('accuracy: ', accuracy)\n",
    "print('classification_report: ', cls_report)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
